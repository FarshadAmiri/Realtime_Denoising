{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "378ce935",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Import our modules\n",
    "from voice_enrollment import VoiceEnrollment, create_voice_database\n",
    "from diarization_processor import DiarizationProcessor\n",
    "from transcription import TranscriptionProcessor\n",
    "from main import process_meeting_audio, quick_diarize, diarize_and_transcribe\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4f5091",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your file paths here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cea3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CONFIGURE THESE PATHS ====\n",
    "\n",
    "# Meeting audio file to process\n",
    "MEETING_AUDIO = \"path/to/your/meeting.wav\"\n",
    "\n",
    "# Speaker voice samples for enrollment\n",
    "SPEAKER_SAMPLES = {\n",
    "    \"John\": [\"path/to/john_sample1.wav\", \"path/to/john_sample2.wav\"],\n",
    "    \"Jane\": [\"path/to/jane_sample.wav\"],\n",
    "    \"Ali\": [\"path/to/ali_sample.wav\"]\n",
    "}\n",
    "\n",
    "# Where to save speaker database\n",
    "SPEAKER_DATABASE = \"speakers_database.json\"\n",
    "\n",
    "# Optional: Path to custom Whisper model\n",
    "WHISPER_MODEL_PATH = None  # or \"path/to/whisper_medium.pt\"\n",
    "\n",
    "# Language (en, fa, ar, etc.) or None for auto-detect\n",
    "LANGUAGE = \"en\"  # Change to \"fa\" for Persian\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = \"diarization_output\"\n",
    "\n",
    "print(\"✓ Configuration set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84abaae3",
   "metadata": {},
   "source": [
    "## Step 1: Create Speaker Database\n",
    "\n",
    "Enroll speakers by providing reference audio samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec21a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create voice database from samples\n",
    "print(\"Creating speaker database...\")\n",
    "\n",
    "enrollment = create_voice_database(\n",
    "    database_path=SPEAKER_DATABASE,\n",
    "    speaker_samples=SPEAKER_SAMPLES\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Database created with {len(enrollment.get_all_speakers())} speakers\")\n",
    "print(f\"Enrolled speakers: {enrollment.get_all_speakers()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1644f8",
   "metadata": {},
   "source": [
    "## Step 2: Quick Diarization (No Transcription)\n",
    "\n",
    "Perform speaker diarization to detect \"who spoke when\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick diarization without transcription\n",
    "print(\"Performing diarization...\\n\")\n",
    "\n",
    "result = quick_diarize(\n",
    "    audio_path=MEETING_AUDIO,\n",
    "    database_path=SPEAKER_DATABASE,\n",
    "    output_dir=OUTPUT_DIR\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Number of speakers detected: {result['num_speakers']}\")\n",
    "print(f\"Identified speakers: {result['identified_speakers']}\")\n",
    "print(f\"Total segments: {len(result['segments'])}\")\n",
    "print(f\"\\nOutput files:\")\n",
    "for key, path in result['output_files'].items():\n",
    "    print(f\"  {key}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3343ef35",
   "metadata": {},
   "source": [
    "## Step 3: View Diarization Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ca1e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 10 segments\n",
    "print(\"Diarization Segments:\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "for i, seg in enumerate(result['segments'][:10], 1):\n",
    "    start = seg['start']\n",
    "    end = seg['end']\n",
    "    speaker = seg['speaker']\n",
    "    identified = \"✓\" if seg.get('identified', False) else \"?\"\n",
    "    \n",
    "    print(f\"{i}. [{start:6.2f}s - {end:6.2f}s] {identified} {speaker}\")\n",
    "\n",
    "if len(result['segments']) > 10:\n",
    "    print(f\"\\n... and {len(result['segments']) - 10} more segments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bc4338",
   "metadata": {},
   "source": [
    "## Step 4: Full Pipeline with Transcription\n",
    "\n",
    "Run complete pipeline with speaker diarization + transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ab4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline: Diarization + Transcription\n",
    "print(\"Running full pipeline with transcription...\\n\")\n",
    "\n",
    "result_full = process_meeting_audio(\n",
    "    meeting_audio_path=MEETING_AUDIO,\n",
    "    voice_embeddings_database_path=SPEAKER_DATABASE,\n",
    "    expected_language=LANGUAGE,\n",
    "    output_transcriptions=True,\n",
    "    transcriptor_model_path=WHISPER_MODEL_PATH,\n",
    "    output_dir=OUTPUT_DIR + \"_with_transcript\"\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"COMPLETE RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Speakers detected: {result_full['num_speakers']}\")\n",
    "print(f\"Identified: {result_full['identified_speakers']}\")\n",
    "print(f\"Segments: {len(result_full['segments'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89022672",
   "metadata": {},
   "source": [
    "## Step 5: View Transcript with Speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee6c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display transcript with speaker labels\n",
    "if 'transcription' in result_full:\n",
    "    print(\"TRANSCRIPT WITH SPEAKER LABELS\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Show first 10 segments with text\n",
    "    for i, seg in enumerate(result_full['segments'][:10], 1):\n",
    "        if 'text' in seg:\n",
    "            print(f\"[{seg['start']:6.2f}s - {seg['end']:6.2f}s]\")\n",
    "            print(f\"{seg['speaker']}: {seg['text']}\")\n",
    "            print()\n",
    "    \n",
    "    if len(result_full['segments']) > 10:\n",
    "        print(f\"... and {len(result_full['segments']) - 10} more segments\\n\")\n",
    "    \n",
    "    # Full transcript\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FULL TRANSCRIPT\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    print(result_full['transcription'])\n",
    "else:\n",
    "    print(\"No transcription available (transcription was disabled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da872cb2",
   "metadata": {},
   "source": [
    "## Step 6: Alternative - Using Direct Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2373575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative method: Direct function call with all parameters\n",
    "result_alt = diarize_and_transcribe(\n",
    "    audio_path=MEETING_AUDIO,\n",
    "    database_path=SPEAKER_DATABASE,\n",
    "    language=LANGUAGE,\n",
    "    whisper_model=WHISPER_MODEL_PATH,\n",
    "    output_dir=\"diarization_alternative\"\n",
    ")\n",
    "\n",
    "print(f\"✓ Processing complete\")\n",
    "print(f\"Results saved to: {result_alt['output_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be0bdd",
   "metadata": {},
   "source": [
    "## Step 7: Save Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4faca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create summary\n",
    "summary = {\n",
    "    \"audio_file\": MEETING_AUDIO,\n",
    "    \"num_speakers\": result_full['num_speakers'],\n",
    "    \"identified_speakers\": result_full['identified_speakers'],\n",
    "    \"enrolled_speakers\": result_full['enrolled_speakers'],\n",
    "    \"total_segments\": len(result_full['segments']),\n",
    "    \"output_files\": result_full['output_files']\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "summary_path = Path(result_full['output_dir']) / \"summary.json\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"✓ Summary saved to: {summary_path}\")\n",
    "print(\"\\nSummary:\")\n",
    "print(json.dumps(summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76148513",
   "metadata": {},
   "source": [
    "## Advanced: Manual Testing of Components\n",
    "\n",
    "Test individual components separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3062a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Voice Enrollment\n",
    "print(\"Testing Voice Enrollment...\")\n",
    "test_enrollment = VoiceEnrollment(\"test_database.json\")\n",
    "\n",
    "# Enroll a test speaker (replace with actual audio path)\n",
    "# test_enrollment.enroll_speaker(\"TestSpeaker\", \"test_audio.wav\")\n",
    "# test_enrollment.save_database()\n",
    "\n",
    "print(\"✓ Voice Enrollment working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e6d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Diarization Processor\n",
    "print(\"Testing Diarization Processor...\")\n",
    "test_diarizer = DiarizationProcessor()\n",
    "\n",
    "# Perform diarization (replace with actual audio path)\n",
    "# test_segments = test_diarizer.perform_diarization(\"test_meeting.wav\")\n",
    "# print(f\"Found {len(test_segments)} segments\")\n",
    "\n",
    "print(\"✓ Diarization Processor working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35797ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Transcription Processor\n",
    "print(\"Testing Transcription Processor...\")\n",
    "test_transcriptor = TranscriptionProcessor(model_name=\"base\")\n",
    "\n",
    "# Transcribe audio (replace with actual audio path)\n",
    "# test_result = test_transcriptor.transcribe_audio(\"test_audio.wav\", language=\"en\")\n",
    "# print(f\"Transcribed {len(test_result['segments'])} segments\")\n",
    "\n",
    "print(\"✓ Transcription Processor working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d0519e",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "Common issues and solutions:\n",
    "\n",
    "1. **GPU Memory Error**: Use smaller Whisper model or switch to CPU\n",
    "2. **Poor Identification**: Enroll speakers with longer/multiple samples\n",
    "3. **Wrong Speaker Count**: Specify `num_speakers` parameter\n",
    "4. **Language Issues**: Explicitly set `expected_language` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec0f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check system resources\n",
    "import torch\n",
    "\n",
    "print(\"System Information:\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e3a3c",
   "metadata": {},
   "source": [
    "## Complete!\n",
    "\n",
    "Your diarization system is now ready to use. Check the output directory for all generated files."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
