{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "378ce935",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01cc841c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir(r\"D:\\Git_repos\\ClearCast\\Nemo-diarization\")\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# IMPORTANT: Reload modules if they were previously imported\n",
    "import importlib\n",
    "if 'diarization_processor' in sys.modules:\n",
    "    importlib.reload(sys.modules['diarization_processor'])\n",
    "if 'voice_enrollment' in sys.modules:\n",
    "    importlib.reload(sys.modules['voice_enrollment'])\n",
    "if 'transcription' in sys.modules:\n",
    "    importlib.reload(sys.modules['transcription'])\n",
    "if 'main' in sys.modules:\n",
    "    importlib.reload(sys.modules['main'])\n",
    "\n",
    "# Import our modules\n",
    "from voice_enrollment import VoiceEnrollment, create_voice_database\n",
    "from diarization_processor import DiarizationProcessor\n",
    "from transcription import TranscriptionProcessor\n",
    "from main import process_meeting_audio, quick_diarize, diarize_and_transcribe\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe1936de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ HuggingFace token loaded\n",
      "✓ huggingface_hub version: 1.2.1\n"
     ]
    }
   ],
   "source": [
    "# Set up HuggingFace token for model downloads\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "HF_TOKEN_PATH = Path(r\"D:\\Git_repos\\ClearCast\\hf_token.txt\")\n",
    "\n",
    "if HF_TOKEN_PATH.exists():\n",
    "    with open(HF_TOKEN_PATH, 'r') as f:\n",
    "        hf_token = f.read().strip()\n",
    "        os.environ['HF_TOKEN'] = hf_token\n",
    "        os.environ['HUGGING_FACE_HUB_TOKEN'] = hf_token\n",
    "        os.environ['HUGGINGFACE_HUB_TOKEN'] = hf_token\n",
    "        os.environ['HF_HOME'] = str(Path.home() / '.cache' / 'huggingface')\n",
    "    print(\"✓ HuggingFace token loaded\")\n",
    "else:\n",
    "    print(\"⚠ HuggingFace token not found at:\", HF_TOKEN_PATH)\n",
    "    print(\"  Models will be downloaded without authentication\")\n",
    "\n",
    "# Fix huggingface_hub version compatibility\n",
    "try:\n",
    "    import huggingface_hub\n",
    "    print(f\"✓ huggingface_hub version: {huggingface_hub.__version__}\")\n",
    "    \n",
    "    # Upgrade if needed\n",
    "    if hasattr(huggingface_hub, 'hf_hub_download'):\n",
    "        import inspect\n",
    "        sig = inspect.signature(huggingface_hub.hf_hub_download)\n",
    "        if 'use_auth_token' in sig.parameters and 'token' not in sig.parameters:\n",
    "            print(\"⚠ Old huggingface_hub version detected. Upgrading...\")\n",
    "            import subprocess\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"huggingface-hub\"])\n",
    "            print(\"✓ huggingface_hub upgraded. Please restart kernel.\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4f5091",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your file paths here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93cea3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration set\n"
     ]
    }
   ],
   "source": [
    "# ==== CONFIGURE THESE PATHS ====\n",
    "\n",
    "# Speaker voice samples for enrollment\n",
    "SPEAKER_SAMPLES = {\n",
    "    \"sp3000\": [r\"D:\\Projects_tmp\\noisy_audio_files\\LibriSpeech\\dev-clean\\3000\\15664\\3000-15664-0024.flac\", \n",
    "               r\"D:\\Projects_tmp\\noisy_audio_files\\LibriSpeech\\dev-clean\\3000\\15664\\3000-15664-0040.flac\"],\n",
    "    \"sp777\" : [r\"D:\\Projects_tmp\\noisy_audio_files\\LibriSpeech\\dev-clean\\777\\126732\\777-126732-0028.flac\",\n",
    "               r\"D:\\Projects_tmp\\noisy_audio_files\\LibriSpeech\\dev-clean\\777\\126732\\777-126732-0025.flac\"],\n",
    "    \"sp422\" : [r\"D:\\Projects_tmp\\noisy_audio_files\\LibriSpeech\\dev-clean\\422\\122949\\422-122949-0021.flac\",\n",
    "               r\"D:\\Projects_tmp\\noisy_audio_files\\LibriSpeech\\dev-clean\\422\\122949\\422-122949-0016.flac\"],\n",
    "    \"sp1993\": [r\"D:\\Projects_tmp\\noisy_audio_files\\LibriSpeech\\dev-clean\\1993\\147964\\1993-147964-0005.flac\",\n",
    "               r\"D:\\Projects_tmp\\noisy_audio_files\\LibriSpeech\\dev-clean\\1993\\147964\\1993-147964-0003.flac\"],\n",
    "}\n",
    "\n",
    "# Where to save speaker database\n",
    "SPEAKER_DATABASE = r\"D:\\Git_repos\\ClearCast\\Nemo-diarization\\outputs\\db\\speakers_db.json\"\n",
    "\n",
    "# Optional: Path to custom Whisper model\n",
    "WHISPER_MODEL_PATH = r\"C:\\Users\\User_1\\.cache\\huggingface\\hub\\models--openai--whisper-medium\"  # or \"path/to/whisper_medium.pt\"\n",
    "\n",
    "# Language (en, fa, ar, etc.) or None for auto-detect\n",
    "LANGUAGE = \"en\"  # Change to \"fa\" for Persian\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = r\"D:\\Git_repos\\ClearCast\\Nemo-diarization\\outputs\\files\"\n",
    "\n",
    "print(\"✓ Configuration set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84abaae3",
   "metadata": {},
   "source": [
    "## Step 1: Create Speaker Database\n",
    "\n",
    "Enroll speakers by providing reference audio samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0ec21a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating speaker database...\n",
      "Loaded the voice encoder model on cuda in 0.17 seconds.\n",
      "✓ Loaded 4 speakers from database\n",
      "✓ Enrolled speaker: sp3000 (from 2 samples)\n",
      "✓ Enrolled speaker: sp777 (from 2 samples)\n",
      "✓ Enrolled speaker: sp422 (from 2 samples)\n",
      "✓ Enrolled speaker: sp1993 (from 2 samples)\n",
      "✓ Database saved to: D:\\Git_repos\\ClearCast\\Nemo-diarization\\outputs\\db\\speakers_db.json\n",
      "\n",
      "✓ Database created with 4 speakers\n",
      "Enrolled speakers: ['sp3000', 'sp777', 'sp422', 'sp1993']\n"
     ]
    }
   ],
   "source": [
    "# Create voice database from samples\n",
    "print(\"Creating speaker database...\")\n",
    "\n",
    "enrollment = create_voice_database(\n",
    "    database_path=SPEAKER_DATABASE,\n",
    "    speaker_samples=SPEAKER_SAMPLES\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Database created with {len(enrollment.get_all_speakers())} speakers\")\n",
    "print(f\"Enrolled speakers: {enrollment.get_all_speakers()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1644f8",
   "metadata": {},
   "source": [
    "## Step 2: Quick Diarization (No Transcription)\n",
    "\n",
    "Perform speaker diarization to detect \"who spoke when\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f9769b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing diarization...\n",
      "\n",
      "============================================================\n",
      "SPEAKER DIARIZATION PIPELINE\n",
      "============================================================\n",
      "Audio file: D:\\Projects_tmp\\noisy_audio_files\\speeches\\1\\concat_1.wav\n",
      "Voice database: D:\\Git_repos\\ClearCast\\Nemo-diarization\\outputs\\db\\speakers_db.json\n",
      "Language: auto-detect\n",
      "Transcription: disabled\n",
      "============================================================\n",
      "\n",
      "[1/4] Loading speaker database...\n",
      "Loaded the voice encoder model on cuda in 0.02 seconds.\n",
      "✓ Loaded 4 speakers from database\n",
      "✓ Loaded 4 enrolled speakers: ['sp3000', 'sp777', 'sp422', 'sp1993']\n",
      "\n",
      "[2/4] Performing speaker diarization...\n",
      "Using device: cuda\n",
      "Loading SpeechBrain models...\n",
      "Warning: Could not load SpeechBrain model: hf_hub_download() got an unexpected keyword argument 'use_auth_token'\n",
      "Continuing with Resemblyzer only...\n",
      "Loaded the voice encoder model on cuda in 0.01 seconds.\n",
      "✓ Models loaded successfully\n",
      "Processing: D:\\Projects_tmp\\noisy_audio_files\\speeches\\1\\concat_1.wav\n",
      "Extracting speaker embeddings...\n",
      "Extracted 87 embeddings\n",
      "Audio duration: 95.61s\n",
      "Clustering speakers...\n",
      "✓ Found 6 speakers\n",
      "✓ Generated 11 segments\n",
      "✓ Results saved to: D:\\Git_repos\\ClearCast\\Nemo-diarization\\outputs\\files\\diarization_raw.json\n",
      "\n",
      "[3/4] Identifying speakers...\n",
      "✓ Identified 9/11 segments\n",
      "\n",
      "[4/4] Skipping transcription (disabled)\n",
      "\n",
      "============================================================\n",
      "PROCESSING COMPLETE\n",
      "============================================================\n",
      "Detected speakers: 6\n",
      "Identified speakers: ['sp422', 'sp3000', 'sp1993', 'sp777']\n",
      "Total segments: 11\n",
      "Output directory: D:\\Git_repos\\ClearCast\\Nemo-diarization\\outputs\\files\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "RESULTS\n",
      "============================================================\n",
      "Number of speakers detected: 6\n",
      "Identified speakers: ['sp422', 'sp3000', 'sp1993', 'sp777']\n",
      "Total segments: 11\n",
      "\n",
      "Output files:\n",
      "  diarization_raw: D:\\Git_repos\\ClearCast\\Nemo-diarization\\outputs\\files\\diarization_raw.json\n",
      "  diarization_identified: D:\\Git_repos\\ClearCast\\Nemo-diarization\\outputs\\files\\diarization_identified.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "D:\\Projects\\venv\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Meeting audio file to process\n",
    "MEETING_AUDIO = r\"D:\\Projects_tmp\\noisy_audio_files\\speeches\\1\\concat_1.wav\"\n",
    "# MEETING_AUDIO = r\"D:\\Projects_tmp\\noisy_audio_files\\speeches\\1\\concat_1_doubled.wav\"\n",
    "# MEETING_AUDIO = r\"D:\\Projects_tmp\\noisy_audio_files\\speeches\\1\\concat_1_1m.wav\"\n",
    "\n",
    "# Quick diarization without transcription\n",
    "print(\"Performing diarization...\\n\")\n",
    "\n",
    "result = quick_diarize(\n",
    "    audio_path=MEETING_AUDIO,\n",
    "    database_path=SPEAKER_DATABASE,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    window_size=1.5,  # Smaller window for better boundary precision\n",
    "    hop_size=0.5      # Smaller hop for more frequent sampling\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Number of speakers detected: {result['num_speakers']}\")\n",
    "print(f\"Identified speakers: {result['identified_speakers']}\")\n",
    "print(f\"Total segments: {len(result['segments'])}\")\n",
    "print(f\"\\nOutput files:\")\n",
    "for key, path in result['output_files'].items():\n",
    "    print(f\"  {key}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3343ef35",
   "metadata": {},
   "source": [
    "## Step 3: View Diarization Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11ca1e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diarization Segments:\n",
      "============================================================\n",
      "\n",
      "Total audio duration: 95.61s\n",
      "\n",
      " 1. [  1.00s -  18.00s] (17.00s) ✓ sp3000\n",
      " 2. [ 18.00s -  31.00s] (13.00s) ✓ sp422\n",
      " 3. [ 31.00s -  36.00s] ( 5.00s) ✓ sp422\n",
      " 4. [ 36.00s -  41.00s] ( 5.00s) ✓ sp777\n",
      " 5. [ 41.00s -  53.00s] (12.00s) ✓ sp3000\n",
      " 6. [ 53.00s -  63.00s] (10.00s) ✓ sp3000\n",
      " 7. [ 63.00s -  74.00s] (11.00s) ✓ sp777\n",
      " 8. [ 74.00s -  75.00s] ( 1.00s) ? Speaker_5\n",
      " 9. [ 75.00s -  86.00s] (11.00s) ✓ sp1993\n",
      "10. [ 86.00s -  84.59s] (-1.41s) ? Speaker_4\n",
      "11. [ 84.59s -  95.61s] (11.02s) ✓ sp3000\n"
     ]
    }
   ],
   "source": [
    "# Display all segments\n",
    "print(\"Diarization Segments:\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Check audio duration\n",
    "if result['segments']:\n",
    "    total_duration = result['segments'][-1]['end']\n",
    "    print(f\"Total audio duration: {total_duration:.2f}s\\n\")\n",
    "\n",
    "for i, seg in enumerate(result['segments'], 1):\n",
    "    start = seg['start']\n",
    "    end = seg['end']\n",
    "    duration = end - start\n",
    "    speaker = seg['speaker']\n",
    "    identified = \"✓\" if seg.get('identified', False) else \"?\"\n",
    "    \n",
    "    print(f\"{i:2d}. [{start:6.2f}s - {end:6.2f}s] ({duration:5.2f}s) {identified} {speaker}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bc4338",
   "metadata": {},
   "source": [
    "## Step 4: Full Pipeline with Transcription\n",
    "\n",
    "Run complete pipeline with speaker diarization + transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "264ab4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing NeMo diarization processor...\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\venv\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (11). ONNX Runtime supports Windows 10 and above, only.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error importing huggingface_hub.hf_api: cannot import name 'HfFolder' from 'huggingface_hub.utils' (D:\\Projects\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\__init__.py)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "NVIDIA NeMo not installed. Please install with:\npip install nemo_toolkit[asr]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mD:\\Git_repos\\ClearCast\\Nemo-diarization\\diarization_processor.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"✓ NeMo ASR imported successfully\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             raise ImportError(\n\u001b[0m\u001b[0;32m     40\u001b[0m                 \u001b[1;34m\"NVIDIA NeMo not installed. Please install with:\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\nemo\\collections\\asr\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# limitations under the License.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnemo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnemo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpackage_info\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\nemo\\collections\\asr\\losses\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# limitations under the License.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnemo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mangularloss\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAngularSoftmaxLoss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnemo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbce_loss\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBCELoss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\nemo\\collections\\asr\\losses\\angularloss.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnemo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLoss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTyping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypecheck\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnemo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneural_types\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelsType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogitsType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLossType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNeuralType\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\nemo\\core\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnemo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneural_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnemo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\nemo\\core\\classes\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhydra\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0momegaconf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\lightning\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfabric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfabric\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFabric\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfabric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseed_everything\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCallback\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLightningDataModule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLightningModule\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\lightning\\pytorch\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfabric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseed_everything\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfabric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarnings\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdisable_possible_user_warnings\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCallback\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLightningDataModule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLightningModule\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# See the License for the specific language governing permissions and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# limitations under the License.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size_finder\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBatchSizeFinder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCallback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\batch_size_finder.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpytorch\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCallback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size_scaling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_scale_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\callback.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpytorch\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSTEP_OUTPUT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\lightning\\pytorch\\utilities\\types.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLRScheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMetric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNotRequired\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRequired\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\torchmetrics\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhamming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindows\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhamming\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m from torchmetrics.aggregation import (  # noqa: E402\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\torchmetrics\\functional\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deprecated\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_retrieval_recall\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mretrieval_recall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deprecated\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_retrieval_reciprocal_rank\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mretrieval_reciprocal_rank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deprecated\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_bleu_score\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deprecated\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_char_error_rate\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mchar_error_rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\torchmetrics\\functional\\text\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m_TRANSFORMERS_GREATER_EQUAL_4_4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbert_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfolm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minfolm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\torchmetrics\\functional\\text\\bert.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m_TRANSFORMERS_GREATER_EQUAL_4_4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\transformers\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m from .utils import (\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\transformers\\dependency_versions_check.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdependency_versions_table\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_version_core\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\transformers\\utils\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlru_cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_full_repo_name\u001b[0m  \u001b[1;31m# for backward compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHF_HUB_DISABLE_TELEMETRY\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mDISABLE_TELEMETRY\u001b[0m  \u001b[1;31m# for backward compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\huggingface_hub\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m   1049\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mError importing \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0msubmod_path\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m: \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m             \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Projects\\venv\\Lib\\site-packages\\huggingface_hub\\hf_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfile_download\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHfFileMetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_hf_file_metadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhf_hub_url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mrepocard_data\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDatasetCardData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModelCardData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSpaceCardData\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m from .utils import (\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[0mDEFAULT_IGNORE_PATTERNS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'HfFolder' from 'huggingface_hub.utils' (D:\\Projects\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize diarization processor\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing NeMo diarization processor...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m processor \u001b[38;5;241m=\u001b[39m \u001b[43mDiarizationProcessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Perform diarization with NeMo (num_speakers is optional - can auto-detect)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mProcessing audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMEETING_AUDIO\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Git_repos\\ClearCast\\Nemo-diarization\\diarization_processor.py:39\u001b[0m, in \u001b[0;36mDiarizationProcessor.__init__\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ NeMo ASR imported successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNVIDIA NeMo not installed. Please install with:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpip install nemo_toolkit[asr]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     42\u001b[0m     )\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiarizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemp_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: NVIDIA NeMo not installed. Please install with:\npip install nemo_toolkit[asr]"
     ]
    }
   ],
   "source": [
    "# Test audio path\n",
    "MEETING_AUDIO = r\"D:\\Projects_tmp\\noisy_audio_files\\output-4-speakers.wav\"\n",
    "\n",
    "# Initialize diarization processor\n",
    "print(\"Initializing NeMo diarization processor...\")\n",
    "processor = DiarizationProcessor()\n",
    "\n",
    "# Perform diarization with NeMo (num_speakers is optional - can auto-detect)\n",
    "print(f\"\\nProcessing audio: {MEETING_AUDIO}\")\n",
    "segments = processor.perform_diarization(\n",
    "    MEETING_AUDIO,\n",
    "    num_speakers=4  # Set to None for auto-detection\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"DIARIZATION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "for i, seg in enumerate(segments, 1):\n",
    "    duration = seg['end'] - seg['start']\n",
    "    print(f\"Segment {i:2d}: {seg['start']:6.2f}s - {seg['end']:6.2f}s ({duration:5.2f}s) | {seg['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89022672",
   "metadata": {},
   "source": [
    "## Step 5: View Transcript with Speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee6c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display transcript with speaker labels\n",
    "if 'transcription' in result_full:\n",
    "    print(\"TRANSCRIPT WITH SPEAKER LABELS\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Show first 10 segments with text\n",
    "    for i, seg in enumerate(result_full['segments'][:10], 1):\n",
    "        if 'text' in seg:\n",
    "            print(f\"[{seg['start']:6.2f}s - {seg['end']:6.2f}s]\")\n",
    "            print(f\"{seg['speaker']}: {seg['text']}\")\n",
    "            print()\n",
    "    \n",
    "    if len(result_full['segments']) > 10:\n",
    "        print(f\"... and {len(result_full['segments']) - 10} more segments\\n\")\n",
    "    \n",
    "    # Full transcript\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FULL TRANSCRIPT\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    print(result_full['transcription'])\n",
    "else:\n",
    "    print(\"No transcription available (transcription was disabled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da872cb2",
   "metadata": {},
   "source": [
    "## Step 6: Alternative - Using Direct Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2373575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative method: Direct function call with all parameters\n",
    "result_alt = diarize_and_transcribe(\n",
    "    audio_path=MEETING_AUDIO,\n",
    "    database_path=SPEAKER_DATABASE,\n",
    "    language=LANGUAGE,\n",
    "    whisper_model=WHISPER_MODEL_PATH,\n",
    "    output_dir=\"diarization_alternative\"\n",
    ")\n",
    "\n",
    "print(f\"✓ Processing complete\")\n",
    "print(f\"Results saved to: {result_alt['output_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be0bdd",
   "metadata": {},
   "source": [
    "## Step 7: Save Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4faca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create summary\n",
    "summary = {\n",
    "    \"audio_file\": MEETING_AUDIO,\n",
    "    \"num_speakers\": result_full['num_speakers'],\n",
    "    \"identified_speakers\": result_full['identified_speakers'],\n",
    "    \"enrolled_speakers\": result_full['enrolled_speakers'],\n",
    "    \"total_segments\": len(result_full['segments']),\n",
    "    \"output_files\": result_full['output_files']\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "summary_path = Path(result_full['output_dir']) / \"summary.json\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"✓ Summary saved to: {summary_path}\")\n",
    "print(\"\\nSummary:\")\n",
    "print(json.dumps(summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76148513",
   "metadata": {},
   "source": [
    "## Advanced: Manual Testing of Components\n",
    "\n",
    "Test individual components separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3062a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Voice Enrollment\n",
    "print(\"Testing Voice Enrollment...\")\n",
    "test_enrollment = VoiceEnrollment(\"test_database.json\")\n",
    "\n",
    "# Enroll a test speaker (replace with actual audio path)\n",
    "# test_enrollment.enroll_speaker(\"TestSpeaker\", \"test_audio.wav\")\n",
    "# test_enrollment.save_database()\n",
    "\n",
    "print(\"✓ Voice Enrollment working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e6d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Diarization Processor\n",
    "print(\"Testing Diarization Processor...\")\n",
    "test_diarizer = DiarizationProcessor()\n",
    "\n",
    "# Perform diarization (replace with actual audio path)\n",
    "# test_segments = test_diarizer.perform_diarization(\"test_meeting.wav\")\n",
    "# print(f\"Found {len(test_segments)} segments\")\n",
    "\n",
    "print(\"✓ Diarization Processor working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35797ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Transcription Processor\n",
    "print(\"Testing Transcription Processor...\")\n",
    "test_transcriptor = TranscriptionProcessor(model_name=\"base\")\n",
    "\n",
    "# Transcribe audio (replace with actual audio path)\n",
    "# test_result = test_transcriptor.transcribe_audio(\"test_audio.wav\", language=\"en\")\n",
    "# print(f\"Transcribed {len(test_result['segments'])} segments\")\n",
    "\n",
    "print(\"✓ Transcription Processor working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d0519e",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "Common issues and solutions:\n",
    "\n",
    "1. **GPU Memory Error**: Use smaller Whisper model or switch to CPU\n",
    "2. **Poor Identification**: Enroll speakers with longer/multiple samples\n",
    "3. **Wrong Speaker Count**: Specify `num_speakers` parameter\n",
    "4. **Language Issues**: Explicitly set `expected_language` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec0f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check system resources\n",
    "import torch\n",
    "\n",
    "print(\"System Information:\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e3a3c",
   "metadata": {},
   "source": [
    "## Complete!\n",
    "\n",
    "Your diarization system is now ready to use. Check the output directory for all generated files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
